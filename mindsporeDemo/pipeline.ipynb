{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8689a830-d87c-432e-85d7-ebdf49fa8585",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlflow boto3 awscli pyarrow sklearn mlflow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "537b2dab-6240-4986-a3fd-74372f7fbed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kfp --upgrade -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e33f1eea-1597-4f2b-b989-d4815da46ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.components as comp\n",
    "import kfp.dsl as dsl\n",
    "from kfp.components import InputPath, OutputPath\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a31f485f-a054-46a4-a644-9cda1f435995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: kfp\n",
      "Version: 1.8.14\n",
      "Summary: KubeFlow Pipelines SDK\n",
      "Home-page: https://github.com/kubeflow/pipelines\n",
      "Author: The Kubeflow Authors\n",
      "Author-email: \n",
      "License: UNKNOWN\n",
      "Location: /opt/conda/lib/python3.8/site-packages\n",
      "Requires: absl-py, click, cloudpickle, Deprecated, docstring-parser, fire, google-api-core, google-api-python-client, google-auth, google-cloud-storage, jsonschema, kfp-pipeline-spec, kfp-server-api, kubernetes, protobuf, pydantic, PyYAML, requests-toolbelt, strip-hints, tabulate, typer, typing-extensions, uritemplate\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "! pip show kfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "284def27-9f6b-40c3-8465-c8aa4840167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data step\n",
    "def load_data():\n",
    "    \n",
    "    return(print('Done!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7dfee977-4149-42ea-b30e-23364b873aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data step\n",
    "def train():\n",
    "    \n",
    "    import sys, subprocess;\n",
    "    subprocess.run([\"python\", \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\"])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install','numpy'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install','mindspore'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install','matplotlib'])\n",
    "    \n",
    "    import numpy as np\n",
    "    import mindspore\n",
    "    import mindspore.nn as nn\n",
    "    import mindspore.ops as ops\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mindspore import Tensor, ms_function\n",
    "    \n",
    "    def random_batch():\n",
    "        random_inputs = []\n",
    "        random_labels = []\n",
    "        random_index = np.random.choice(range(len(skip_grams)), batch_size, replace=False)\n",
    "\n",
    "        for i in random_index:\n",
    "            random_inputs.append(np.eye(voc_size)[skip_grams[i][0]])  # target\n",
    "            random_labels.append(skip_grams[i][1])  # context word\n",
    "\n",
    "        return random_inputs, random_labels\n",
    "    \n",
    "    class Word2Vec(nn.Cell):\n",
    "        def __init__(self, voc_size, embed_size):\n",
    "            super(Word2Vec, self).__init__()\n",
    "            # W and WT is not Traspose relationship\n",
    "            self.W = nn.Dense(voc_size, embed_size, has_bias=False) # voc_size > embedding_size Weight\n",
    "            self.WT = nn.Dense(embed_size, voc_size, has_bias=False) # embedding_size > voc_size Weight\n",
    "\n",
    "        def construct(self, X):\n",
    "            # X : [batch_size, voc_size]\n",
    "            hidden_layer = self.W(X) # hidden_layer : [batch_size, embedding_size]\n",
    "            output_layer = self.WT(hidden_layer) # output_layer : [batch_size, voc_size]\n",
    "            return output_layer\n",
    "    \n",
    "    batch_size = 2 # mini-batch size\n",
    "    embed_size = 2 # embedding size\n",
    "\n",
    "    sentences = [\"apple banana fruit\", \"banana orange fruit\", \"orange banana fruit\",\n",
    "                 \"dog cat animal\", \"cat monkey animal\", \"monkey dog animal\"]\n",
    "\n",
    "    word_sequence = \" \".join(sentences).split()\n",
    "    word_list = \" \".join(sentences).split()\n",
    "    word_list = list(set(word_list))\n",
    "    word_dict = {w: i for i, w in enumerate(word_list)}\n",
    "    voc_size = len(word_list)\n",
    "    \n",
    "    skip_grams = []\n",
    "    for i in range(1, len(word_sequence) - 1):\n",
    "        target = word_dict[word_sequence[i]]\n",
    "        context = [word_dict[word_sequence[i - 1]], word_dict[word_sequence[i + 1]]]\n",
    "        for w in context:\n",
    "            skip_grams.append([target, w])\n",
    "            \n",
    "    model = Word2Vec(voc_size, embed_size)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = nn.Adam(model.trainable_params(), learning_rate=0.001)\n",
    "    \n",
    "    def forward(inputs, targets):\n",
    "        logits = model(inputs)\n",
    "        loss = criterion(logits, targets)\n",
    "        return loss\n",
    "    \n",
    "    grad_fn = ops.value_and_grad(forward, None, optimizer.parameters)\n",
    "    \n",
    "    @ms_function\n",
    "    def train_step(inputs, targets):\n",
    "        loss, grads = grad_fn(inputs, targets)\n",
    "        optimizer(grads)\n",
    "        return loss\n",
    "    \n",
    "    model.set_train()\n",
    "\n",
    "    epoch = 5000\n",
    "    for step in range(epoch):\n",
    "        input_batch, target_batch = random_batch()\n",
    "        input_batch = Tensor(input_batch, mindspore.float32)\n",
    "        target_batch = Tensor(target_batch, mindspore.int32)\n",
    "        loss = train_step(input_batch, target_batch)\n",
    "        if (step + 1) % 1000 == 0:\n",
    "            print('Epoch:', '%04d' % (step + 1), 'cost = ', '{:.6f}'.format(loss.asnumpy()))\n",
    "            \n",
    "    for i, label in enumerate(word_list):\n",
    "        W, WT = model.get_parameters()\n",
    "        x, y = W[0][i].asnumpy(), W[1][i].asnumpy()\n",
    "        plt.scatter(x, y)\n",
    "        plt.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points', ha='right', va='bottom')\n",
    "    plt.show()\n",
    "    \n",
    "    return(print('Done!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6f1d4c8c-d20c-448c-af3e-14c594b31a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create light weight components\n",
    "load_op = comp.create_component_from_func(load_data,base_image=\"python:3.9\")\n",
    "train_op = comp.create_component_from_func(train,base_image=\"python:3.9\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c8e5391c-6322-4bf1-9afa-74453760f379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline\n",
    "@dsl.pipeline(name=\"mindspore_example\", \n",
    "              description=\"Mindspore example\")\n",
    "\n",
    "# Define parameters to be fed into pipeline\n",
    "def mindspore_example(\n",
    "                             dataset: str,\n",
    "                            ):\n",
    "\n",
    "    vop = dsl.VolumeOp(\n",
    "    name=\"create_volume\",\n",
    "    resource_name=\"data-volume\", \n",
    "    size=\"2Gi\", \n",
    "    modes=dsl.VOLUME_MODE_RWO)\n",
    "    \n",
    "    load_container = load_op().add_pvolumes({\"/mnt\": vop.volume})\n",
    "    # Create transform container.\n",
    "    train_container = train_op().after(load_container).add_pvolumes({\"/mnt\": vop.volume})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ac14b7ca-3d86-4e9d-a3a7-158504f2afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create client that would enable communication with the Pipelines API server \n",
    "client = kfp.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d92dde11-ec72-42e9-9bf8-9d8d8e825a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/ac29ab84-ea45-4666-bd99-2e4ab1ceec00\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/c7c4fb94-2558-48a9-828f-ca6c24d01aa0\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_func = mindspore_example\n",
    "\n",
    "experiment_name = 'mindspore_example'\n",
    "run_name = pipeline_func.__name__ + ' run1'\n",
    "\n",
    "arguments = {\n",
    "             \"dataset\": \"dataset\",\n",
    "            }\n",
    "\n",
    "# Compile pipeline to generate compressed YAML definition of the pipeline.\n",
    "kfp.compiler.Compiler().compile(pipeline_func,  \n",
    "  '{}.zip'.format(experiment_name))\n",
    "\n",
    "# Submit pipeline directly from pipeline function\n",
    "run_result = client.create_run_from_pipeline_func(pipeline_func, \n",
    "                                                  experiment_name=experiment_name, \n",
    "                                                  run_name=run_name, \n",
    "                                                  arguments=arguments\n",
    "                                                 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
